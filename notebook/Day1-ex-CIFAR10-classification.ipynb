{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XEunhe34RByS"},"outputs":[],"source":["# Google Driveのマウント\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# 目的の場所（フォルダ・ディレクトリ）へ移動（各自の環境で適宜修正）\n","%cd \"/content/drive/MyDrive/Colab Notebooks/JKJ1A/\"\n","%ls"]},{"cell_type":"markdown","metadata":{"id":"Uv6erl1c1rF9"},"source":["---\n","# 課題\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mKE7C-A1oUc3"},"source":["## 課題１\n","\n","`train_cifar10.py`を作成せよ．`src`に補助用のテンプレートがあるのでそれを完成させよ．\n","\n","- `lenet.py`にはネットワークの定義を書く\n","- `cifar10.py`には`load_data()`の定義を書く\n","- `train_cifar10.py`にはネットワークの訓練を書く\n","その際，\n","- 実験時間では学習データ数を制限したが，全てのデータを利用して学習せよ\n","```\n","trainloader, testloader, classes = load_data(batch_size, use_all=True)\n","```\n","の`use_all=True`のようにすれば良い．\n","\n","作成した.pyファイルを以下のように実行せよ．"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOaSl6ruZccP"},"outputs":[],"source":["%%time\n","!python src/train_cifar10.py --nepochs 2 --batch_size 128 --lr 0.01 --save_model_name 'model/model_cifar10_lenet.pth'"]},{"cell_type":"markdown","metadata":{"id":"XOG36_AE0p9f"},"source":["学習したモデルをロードし，訓練データ，テストデータでの精度を計算・表示せよ．\n","\n","上のコードで学習後に出る精度と一致することを確認せよ．"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50rMDWPHpMEK"},"outputs":[],"source":["# `model_cifar10_day1.pth`をロードしてください．\n","\n","net = ...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snAOvqvRpSoU"},"outputs":[],"source":["# test()関数で訓練データ・テストデータでの分類精度を計算・表示してください\n","import sys\n","sys.path.append('src')  # srcの中のファイルがimportできるようになる\n","from train_cifar10 import test\n","from cifar10 import load_data\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"98IInQX92Uzi"},"source":["## 課題２（重要）\n","**この課題の結果は次回の実験で利用するので必ず行うこと**\n","\n","\n","VGG11モデルでCIFAR10を学習せよ．課題１のコードを次のように微修正すれば良い．\n","\n","- `from lenet import Net` -> `from vgg import VGG as Net`\n","- `net = Net()` -> `net = Net('VGG11')`\n","\n","学習したモデルの分類精度を課題１の結果と比較せよ．学習したモデル名は`model_cifar10.pth`として`model/`下に保存せよ．テストデータでの分類精度は80%を超えるようにせよ（`nepochs`や`lr`を調整）．友人などと協力して，適当なパラメータを手分けして探すなどすると効率が良い．"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIg_D-2A_YqT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"GshVN9jf1sLJ"},"source":["## 課題３\n","\n","CIFAR10ではなくFashionMNISTを学習し，学習のログと分類精度を表示せよ（コードは`train_fmnist.py`とする）．\n"]},{"cell_type":"markdown","metadata":{"id":"WGx6qp9s1xJM"},"source":["まず学習の前に，FashionMNISTがどのようなデータを含むか，何枚か画像とラベルを表示させてみよ（`Day1-CIFAR10-classification.ipynb`内のコードを参考にせよ）"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1631598523416,"user":{"displayName":"Hiroshi Kera","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01053422096626415082"},"user_tz":-540},"id":"p8JM88PB1sw4"},"outputs":[],"source":["# FashionMNISTの画像を何枚か表示\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8d6EhNKq3g8c"},"source":["さて，学習のための作業の方針は次のようになる．課題１の`load_data()`を修正し，`fmnist.py`を作る．\n","\n","- `load_data()`の`transform`を以下のようにする\n","```\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))]\n","        )\n","```\n","\n","- `torchvision.datasets.CIFAR10`と`classes`も修正する（ほぼ自明な修正．わからなければ少し検索してみよ）．\n","\n","またモデルは次のモデルを利用せよ（`mlp.py`として保存し，train_fmnist.py内で読み込むこと）．\n","```\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","    def __init__(self):   \n","        super().__init__()\n","        self.width = 128\n","        self.fc1 = nn.Linear(28*28, self.width)  # 入力28*28次元, 出力128次元\n","        self.fc2 = nn.Linear(self.width, self.width)\n","        self.fc3 = nn.Linear(self.width, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28*28)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnKiDZ56_aGU"},"outputs":[],"source":["%%time\n","#以下を実行できれば良い．\n","!python src/train_fmnist.py ....."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JrPP2Na_1j3J"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"cMQXCxMH62fu"},"source":["## 課題4 （最終レポート課題）\n","\n","**この内容は最終レポートに含める課題の一つとする**\n","\n","モデルの表現力は学習可能なパラメタ数と関係がある．直感的には，学習可能なパラメタ数が多いほど複雑な関数を表現でき，難しい問題が解けると考えられる．次の課題に取り組め．\n","\n","1. レイヤー数（`nn.Linear`の数）を固定した時，各中間層のユニット数（`self.width`の値）の変化に対し，学習結果はどのようになるだろうか．\n","2. 逆に，各中間層のユニット数を固定した時，レイヤー数を変化させると学習結果はどのようになるだろうか．\n","3. 深いネットワーク（レイヤー数が多いネットワーク）と広いネットワーク（各レイヤーのユニット数が多い），どちらが良いだろうか．（ほぼ）同じパラメタ数の場合で比較せよ．\n","\n","文献調査を行い，どのような傾向があるか知った上でそれを再現しても良い．その場合は参考文献を示すこと．\n","\n","---\n","\n","*補足（1に関して）：課題3の`mlp.py`に定義したモデルに関して，ネットワークの幅`self.width`を何パターンか変化させ，FashionMNIST学習後の分類精度をプロットする（横軸`width`, 縦軸は分類精度）．*\n","\n","*補足（2に関して）：課題3の`mlp.py`を参考に異なるレイヤー数のモデルを定義することになる．*\n","\n","*補足（3に関して）：\n","`nn.Linear`は全結合層と呼ばれ，入力$x$に対し変換$Wx+b$を行い$z$を出力する（$W,b$は学習されるパラメタ）．$x,z$がそれぞれ$n,m$次元ベクトルの場合，全結合層一つ当たりのパラメタ数が$n,m$で表現できると思う．「同じパラメタ数」という条件が何を意味するのかよく考えること．*\n","\n","*補足：\n","`plt.show()`の一つ前で`plt.savefig('画像名.pdf')`とすると，画像を保存できる．*\n","\n","```\n","import matplotlib.pyplot as plt \n","\n","parameter = ...\n","accs = ...\n","\n","plt.plot(parameter, accs)\n","plt.savefig('result.pdf')\n","plt.show()\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvEEGD8Q-l15"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN6vtGmJKfywEOZPFhn4DSb","collapsed_sections":[],"name":"Day1-ex-CIFAR10-classification.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
