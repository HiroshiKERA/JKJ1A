{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day1-ex-CIFAR10-classification.ipynb","provenance":[],"collapsed_sections":["mKE7C-A1oUc3"],"authorship_tag":"ABX9TyNbHQC6MJQUGDix0+HGvsSF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEunhe34RByS","executionInfo":{"status":"ok","timestamp":1629200112815,"user_tz":-540,"elapsed":22338,"user":{"displayName":"Hiroshi Kera","photoUrl":"","userId":"01053422096626415082"}},"outputId":"12c4ce45-d7e0-4ef6-a8dc-ead8649033bc"},"source":["# Google Driveのマウント\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# 目的の場所（フォルダ・ディレクトリ）へ移動（各自の環境で適宜修正）\n","%cd \"/content/drive/MyDrive/Colab Notebooks/情報工学実験1A/\"\n","%ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n","/content/drive/MyDrive/Colab Notebooks/情報工学実験1A\n","\u001b[0m\u001b[01;34mbackyard\u001b[0m/  \u001b[01;34mdata\u001b[0m/  \u001b[01;34mmodel\u001b[0m/  \u001b[01;34mnotebook\u001b[0m/  \u001b[01;34msrc_day1\u001b[0m/  \u001b[01;34msrc_day1_ans\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Uv6erl1c1rF9"},"source":["---\n","# 課題\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mKE7C-A1oUc3"},"source":["## 課題１\n","\n","`train_cifar10.py`を作成せよ．`src_day1`にテンプレートがあるのでそれを完成させよ．\n","\n","- `lenet.py`にはネットワークの定義を書く\n","- `cifar10.py`には`load_data()`の定義を書く\n","- `train_cifar10.py`にはネットワークの訓練を書く\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOaSl6ruZccP","executionInfo":{"status":"ok","timestamp":1629012903769,"user_tz":-540,"elapsed":23656,"user":{"displayName":"Hiroshi Kera","photoUrl":"","userId":"01053422096626415082"}},"outputId":"8688ef3c-0582-4422-f52e-6a6df91e0534"},"source":["%%time\n","!python src_day1/train_cifar10.py --nepochs 2 --batch_size 128 --lr 0.001 --save_model_name 'model/model_cifar10_day1.pth'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["using device: cuda:0\n","Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","[epoch  1] loss: 2.302\n","[epoch  2] loss: 2.285\n","Training completed\n","CPU times: user 139 ms, sys: 50 ms, total: 189 ms\n","Wall time: 23.3 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"50rMDWPHpMEK"},"source":["# `model_cifar10_day1.pth`をロードしてください．\n","\n","net = ...\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"snAOvqvRpSoU"},"source":["# test()関数で訓練データ・テストデータでの分類精度を計算・表示してください\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"98IInQX92Uzi"},"source":["## 課題２（重要）\n","**この課題の結果は次回の実験で利用するので必ず行うこと**\n","\n","\n","VGG11モデルでCIFAR10を学習せよ．課題１のコードを次のように微修正すれば良い．\n","\n","- `from lenet import Net` -> `from VGG import VGG as Net`\n","- `net = Net()` -> `net = Net('VGG11')`\n","\n","学習したモデルの分類精度を課題１の結果と比較せよ．学習したモデル名は`model_cifar10.pth`として`model`下に保存せよ．モデルのテストデータでの分類精度は80%を超えるようにせよ（`nepochs`や`lr`を調整）．"]},{"cell_type":"code","metadata":{"id":"aIg_D-2A_YqT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8d6EhNKq3g8c"},"source":["## 課題３\n","\n","CIFAR10ではなくFashionMNISTを学習し，学習のログと分類精度を表示せよ（コードは`train_fmnist.py`とする）．課題１の`load_data()`を修正し，`fmnist.py`を作る．\n","\n","- `load_data()`の`transform`を以下のようにする\n","```\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))]\n","        )\n","```\n","\n","- `torchvision.datasets.CIFAR10`と`classes`も修正する（ほぼ自明な修正．わからなければ少し検索してみよ）．\n","\n","またモデルは次のモデルを利用せよ（`mlp.py`として保存し，train_fmnist.py内で読み込むこと）．\n","```\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","    def __init__(self):   \n","        super().__init__()\n","        self.width = 128\n","        self.fc1 = nn.Linear(28*28, self.width)  # 入力28*28次元, 出力128次元\n","        self.fc2 = nn.Linear(self.width, self.width)\n","        self.fc3 = nn.Linear(self.width, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28*28)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","```"]},{"cell_type":"code","metadata":{"id":"WnKiDZ56_aGU"},"source":["%%time\n","#以下を実行できれば良い．\n","!python train_fmnist.py ....."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cMQXCxMH62fu"},"source":["## 課題4 （最終レポート課題）\n","\n","**この内容は最終レポートに含める課題の一つとする**\n","\n","モデルの表現力は学習可能なパラメタ数と関係がある．直感的には，学習可能なパラメタ数が多いほど複雑な関数を表現でき，難しい問題が解けると考える．次の課題に取り組め．\n","\n","1. レイヤー数（nn.Linearの数）を固定した時，ユニット数の変化に対し，学習結果はどのようになるだろうか．\n","2. 深いネットワーク（レイヤー数が多いネットワーク）と広いネットワーク（各レイヤーのユニット数が多い），どちらが良いだろうか．同じパラメータ数の場合で比較せよ．\n","\n","文献調査を行い，どのような傾向があるか知った上でそれを再現しても良い．その場合は参考文献を示すこと．\n","\n","---\n","\n","*補足（1に関して）：ネットワークの幅`self.width`を何パターンか変化させ，学習後の分類精度をプロットする（横軸`width`, 縦軸は分類精度）．当然だが，それ以外の条件は固定すること．*\n","\n","*補足（2に関して）：\n","`nn.Linear`は全結合層と呼ばれ，入力$x$に対し変換$Wx+b$を行い$y$を出力する（$W,b$は学習されるパラメタ）．$x,y$がそれぞれ$n,m$次元ベクトルの場合，全結合層一つ当たりのパラメタ数が$n,m$で表現できると思う．*\n","\n","*補足：\n","`plt.show()`の一つ前で`plt.savefig('画像名.pdf')`とすると，画像を保存できる．*\n","\n","```\n","import matplotlib.pyplot as plt \n","\n","parameter = ...\n","accs = ...\n","\n","plt.plot(parameter, accs)\n","plt.savefig('result.pdf')\n","plt.show()\n","```"]},{"cell_type":"code","metadata":{"id":"KvEEGD8Q-l15"},"source":[""],"execution_count":null,"outputs":[]}]}