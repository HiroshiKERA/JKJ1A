{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"Day1-ex-CIFAR10-classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN6vtGmJKfywEOZPFhn4DSb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"source":["# Google Driveのマウント\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# 目的の場所（フォルダ・ディレクトリ）へ移動（各自の環境で適宜修正）\n","%cd \"/content/drive/MyDrive/Colab Notebooks/JKJ1A/\"\n","%ls"],"outputs":[],"metadata":{"id":"XEunhe34RByS"}},{"cell_type":"markdown","source":["---\n","# 課題\n","\n"],"metadata":{"id":"Uv6erl1c1rF9"}},{"cell_type":"markdown","source":["## 課題１\n","\n","`train_cifar10.py`を作成せよ．`src`に補助用のテンプレートがあるのでそれを完成させよ．\n","\n","- `lenet.py`にはネットワークの定義を書く\n","- `cifar10.py`には`load_data()`の定義を書く\n","- `train_cifar10.py`にはネットワークの訓練を書く\n","その際，\n","- 実験時間では学習データ数を制限したが，全てのデータを利用して学習せよ\n","```\n","trainloader, testloader, classes = load_data(batch_size, use_all=True)\n","```\n","の`use_all=True`のようにすれば良い．\n","\n","作成した.pyファイルを以下のように実行せよ．"],"metadata":{"id":"mKE7C-A1oUc3"}},{"cell_type":"code","execution_count":null,"source":["%%time\n","!python src/train_cifar10.py --nepochs 2 --batch_size 128 --lr 0.01 --save_model_name 'model/model_cifar10_lenet.pth'"],"outputs":[],"metadata":{"id":"XOaSl6ruZccP"}},{"cell_type":"markdown","source":["学習したモデルをロードし，訓練データ，テストデータでの精度を計算・表示せよ．\n","\n","上のコードで学習後に出る精度と一致することを確認せよ．"],"metadata":{"id":"XOG36_AE0p9f"}},{"cell_type":"code","execution_count":null,"source":["# `model_cifar10_day1.pth`をロードしてください．\n","\n","net = ...\n"],"outputs":[],"metadata":{"id":"50rMDWPHpMEK"}},{"cell_type":"code","execution_count":null,"source":["# test()関数で訓練データ・テストデータでの分類精度を計算・表示してください\n","import sys\n","sys.path.append('src')  # srcの中のファイルがimportできるようになる\n","from train_cifar10 import test\n","from cifar10 import load_data\n","\n","..."],"outputs":[],"metadata":{"id":"snAOvqvRpSoU"}},{"cell_type":"markdown","source":["## 課題２（重要）\n","**この課題の結果は次回の実験で利用するので必ず行うこと**\n","\n","\n","VGG11モデルでCIFAR10を学習せよ．課題１のコードを次のように微修正すれば良い．\n","\n","- `from lenet import Net` -> `from vgg import VGG as Net`\n","- `net = Net()` -> `net = Net('VGG11')`\n","\n","学習したモデルの分類精度を課題１の結果と比較せよ．学習したモデル名は`model_cifar10.pth`として`model/`下に保存せよ．テストデータでの分類精度は80%を超えるようにせよ（`nepochs`や`lr`を調整）．友人などと協力して，適当なパラメータを手分けして探すなどすると効率が良い．"],"metadata":{"id":"98IInQX92Uzi"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"aIg_D-2A_YqT"}},{"cell_type":"markdown","source":["## 課題３\n","\n","CIFAR10ではなくFashionMNISTを学習し，学習のログと分類精度を表示せよ（コードは`train_fmnist.py`とする）．\n"],"metadata":{"id":"GshVN9jf1sLJ"}},{"cell_type":"markdown","source":["まず学習の前に，FashionMNISTがどのようなデータを含むか，何枚か画像とラベルを表示させてみよ（`Day1-CIFAR10-classification.ipynb`内のコードを参考にせよ）"],"metadata":{"id":"WGx6qp9s1xJM"}},{"cell_type":"code","execution_count":1,"source":["# FashionMNISTの画像を何枚か表示\n","\n"],"outputs":[],"metadata":{"id":"p8JM88PB1sw4","executionInfo":{"status":"ok","timestamp":1631598523416,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hiroshi Kera","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01053422096626415082"}}}},{"cell_type":"markdown","source":["さて，学習のための作業の方針は次のようになる．課題１の`load_data()`を修正し，`fmnist.py`を作る．\n","\n","- `load_data()`の`transform`を以下のようにする\n","```\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))]\n","        )\n","```\n","\n","- `torchvision.datasets.CIFAR10`と`classes`も修正する（ほぼ自明な修正．わからなければ少し検索してみよ）．\n","\n","またモデルは次のモデルを利用せよ（`mlp.py`として保存し，train_fmnist.py内で読み込むこと）．\n","```\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","    def __init__(self):   \n","        super().__init__()\n","        self.width = 128\n","        self.fc1 = nn.Linear(28*28, self.width)  # 入力28*28次元, 出力128次元\n","        self.fc2 = nn.Linear(self.width, self.width)\n","        self.fc3 = nn.Linear(self.width, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28*28)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","```"],"metadata":{"id":"8d6EhNKq3g8c"}},{"cell_type":"code","execution_count":null,"source":["%%time\n","#以下を実行できれば良い．\n","!python src/train_fmnist.py ....."],"outputs":[],"metadata":{"id":"WnKiDZ56_aGU"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"JrPP2Na_1j3J"}},{"cell_type":"markdown","source":["## 課題4 （最終レポート課題）\n","\n","**この内容は最終レポートに含める課題の一つとする**\n","\n","モデルの表現力は学習可能なパラメタ数と関係がある．直感的には，学習可能なパラメタ数が多いほど複雑な関数を表現でき，難しい問題が解けると考える．次の課題に取り組め．\n","\n","1. レイヤー数（nn.Linearの数）を固定した時，ユニット数の変化に対し，学習結果はどのようになるだろうか．\n","2. 深いネットワーク（レイヤー数が多いネットワーク）と広いネットワーク（各レイヤーのユニット数が多い），どちらが良いだろうか．同じパラメータ数の場合で比較せよ．\n","\n","文献調査を行い，どのような傾向があるか知った上でそれを再現しても良い．その場合は参考文献を示すこと．\n","\n","---\n","\n","*補足（1に関して）：課題3の`mlp.py`に保存したモデルに関して，ネットワークの幅`self.width`を何パターンか変化させ，FashionMNIST学習後の分類精度をプロットする（横軸`width`, 縦軸は分類精度）．当然だが，それ以外の条件は固定すること．*\n","\n","*補足（2に関して）：\n","`nn.Linear`は全結合層と呼ばれ，入力$x$に対し変換$Wx+b$を行い$y$を出力する（$W,b$は学習されるパラメタ）．$x,y$がそれぞれ$n,m$次元ベクトルの場合，全結合層一つ当たりのパラメタ数が$n,m$で表現できると思う．*\n","\n","*補足：\n","`plt.show()`の一つ前で`plt.savefig('画像名.pdf')`とすると，画像を保存できる．*\n","\n","```\n","import matplotlib.pyplot as plt \n","\n","parameter = ...\n","accs = ...\n","\n","plt.plot(parameter, accs)\n","plt.savefig('result.pdf')\n","plt.show()\n","```"],"metadata":{"id":"cMQXCxMH62fu"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"KvEEGD8Q-l15"}}]}