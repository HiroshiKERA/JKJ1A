{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Day3-JKJ1Adataset.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPXadurFboZCLRF9ktGsqqO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEunhe34RByS","executionInfo":{"status":"ok","timestamp":1634263647793,"user_tz":-540,"elapsed":540,"user":{"displayName":"Hiroshi Kera","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01053422096626415082"}},"outputId":"76f25bbc-b888-4415-a78d-f54d1c18a834"},"source":["# Google Driveのマウント\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# 目的の場所（フォルダ・ディレクトリ）へ移動（各自の環境で適宜修正）\n","%cd \"/content/drive/MyDrive/Colab Notebooks/JKJ1A/\"\n","%ls"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/JKJ1A\n","\u001b[0m\u001b[01;34mbackyard\u001b[0m/  \u001b[01;34mdata\u001b[0m/  __init__.py  \u001b[01;34mmodel\u001b[0m/  \u001b[01;34mnotebook\u001b[0m/  \u001b[01;34mnotebook_ans\u001b[0m/  \u001b[01;34msrc\u001b[0m/  \u001b[01;34msrc_ans\u001b[0m/\n"]}]},{"cell_type":"markdown","metadata":{"id":"G5pbOn1kterk"},"source":["# 概要\n","\n","Day1, Day2でPythonおよびPytorchにある程度慣れ親しんだと思います．これまではCIFAR10やMNISTといった標準的な「扱いやすい」データセットを利用しました．今回から最終レポートに向けて，初日に自分たちで収集したデータセットで分類などを行ってもらいます．仮にJKJ1Aデータセットと呼びます．\n"]},{"cell_type":"markdown","metadata":{"id":"SsWJAwyuup6r"},"source":["---\n","# JKJ1Aデータセット\n","\n","JKJ1Aに対して，CIFAR10，FMNISTと同様`load_data`読み込めるよう準備しました（`jkj1a.py`参照）．今までのデータセットと同様，JKJ1Aは（画像，ラベル）対のデータセットです．ただし今までは1枚の画像xに対するラベルyはクラスを表す数字（例えば`y=0`）でしたが，JKJ1Aではその代わり，ラベルy皆さんの投票結果を表すヒストグラムとなっています．\n","\n","具体的には，JKJ1Aの（画像x，ラベルy）は次のようになっています．\n","- 画像x：CIFAR10と同様，3 x 32 x 32の画像\n","- ラベルy：7段階の投票結果を反映した7次元のベクトル．長さが1になるよう正規化している．\n","\n","なお，`beauty`と`pleasure`という二つの基準についての投票を行なった．`load_data`を用いる際に，'load_data(batch_size=4, metric='beauty')'のようにすることで基準の選択ができる．\n"]},{"cell_type":"markdown","metadata":{"id":"GatnnPfCwRny"},"source":["---\n","## 実験課題\b１ (10分)\n","\n","JKJ1Aを`jkj1a.py`の`load_data`を利用してデータセットを読み込み，何枚か画像を表示させよ．またラベルに関しても，プロットしてみて投票の様子を調べよ`plt.plot(y)`のようにするとプロットできる（`y`は7次元ベクトル）．\n"]},{"cell_type":"code","metadata":{"id":"PwvhX6Czyu8a"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SfQAWGXb3rcZ"},"source":["## 実験課題\b２ (20分)\n","\n","高い点に投票を多く得ている画像，逆に低い点の投票が多い画像を何枚か表示して，どのような感じか見てみよ．また，'beauty', 'pleasant'の二つの基準で，投票の様子が「大きく異なる」画像や，投票の様子が「よく似ている」画像を探索してみよ．「異なる」「似ている」はラベルベクトル間の距離などで定義すると良い．\n","\n","使いそうな関数\n","- `torch.norm()`\n","- `torch.argmin()`\n","- `torch.argmax()`\n","- `torch.topk()`\n","- `torch.sort()`\n","- `torch.argsort()`\n","\n","使い方は適当に検索すると見つかる（公式ドキュメントでもいいが，Qiitaなどのブログ記事も参考になる）．\n"]},{"cell_type":"markdown","metadata":{"id":"wDlzYda4ulv5"},"source":["---\n","## 実験課題\b３ (20分)\n","\n","CIFAR10で学習済みのVGGモデルでJKJ1Aを分類してみよ．分類されたクラスごとに画像を表示してみよ．クラスごとに共通の特徴が見られるだろうか？ adversarial trainingをしたVGGモデルではどうだろうか？"]},{"cell_type":"code","metadata":{"id":"Y0Dh2L1uUK5N","executionInfo":{"status":"ok","timestamp":1634264974609,"user_tz":-540,"elapsed":326,"user":{"displayName":"Hiroshi Kera","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01053422096626415082"}}},"source":[""],"execution_count":18,"outputs":[]}]}